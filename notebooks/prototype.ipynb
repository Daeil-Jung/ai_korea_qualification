{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib\n",
    "# !python -m pip install numpy scipy matplotlib ipython jupyter pandas sympy nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, datetime, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# memory 관련 이슈를 해결하기 위한 코드\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "# np.random.seed(42)\n",
    "random.seed(12345)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# 사전 설정을 위한 세팅\n",
    "epochs = 256\n",
    "image_size = 256\n",
    "batch = 32\n",
    "\n",
    "# Directory check\n",
    "logdir = '../logs'\n",
    "if not os.path.isdir(logdir):\n",
    "    os.mkdir(logdir)\n",
    "    os.mkdir(logdir + \"/disease\")\n",
    "    os.mkdir(logdir + \"/plant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Read dataframe from tsv file\n",
    "train_df = pd.read_csv(\"../data/train/train.tsv\", sep='\\t', header=None)\n",
    "train_df.columns = ['filename', 'plant', 'disease']\n",
    "\n",
    "test_df = pd.read_csv(\"test.tsv\", sep='\\t', header=None)\n",
    "test_df.columns = ['filename']\n",
    "\n",
    "# for categorical labels\n",
    "train_df[['plant', 'disease']] = train_df[['plant', 'disease']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# declare image generator\n",
    "train_image_generator = ImageDataGenerator(rotation_range=5, horizontal_flip=True, validation_split=0.25) # Generator for our training, validation data\n",
    "test_image_generator = ImageDataGenerator() # Generator for our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                           directory=\"../data/train\",\n",
    "                                                           x_col=\"filename\",\n",
    "                                                           y_col=\"plant\",\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           subset='training',\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(image_size,image_size),\n",
    "                                                           batch_size=batch)\n",
    "\n",
    "valid_data_gen = train_image_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                           directory=\"../data/train\",\n",
    "                                                           x_col=\"filename\",\n",
    "                                                           y_col=\"plant\",\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           subset='validation',\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(image_size,image_size),\n",
    "                                                           batch_size=batch)\n",
    "\n",
    "test_data_gen = test_image_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                                         directory=\"../data/test\",\n",
    "                                                         x_col=\"filename\",\n",
    "                                                         y_col=None,\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=False,\n",
    "                                                         target_size=(image_size,image_size),\n",
    "                                                         batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)\n",
    "\n",
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img/225)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plotImages(sample_training_images[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Call bottom model\n",
    "inputs = Input(shape = (image_size, image_size, 3))\n",
    "bot_model = EfficientNetB2(weights='imagenet', input_tensor=inputs, classifier_activation=None, include_top=False)\n",
    "# Rebuild top\n",
    "x = GlobalAveragePooling2D(name=\"avg_pool\")(bot_model.output)\n",
    "x = BatchNormalization(name=\"bn_avg_pool\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(176, activation=\"swish\", name=\"top_dense_1\")(x)\n",
    "x = Dense(22, activation=\"relu\", name=\"top_dense_2\")(x)\n",
    "outputs = Dense(8, activation=\"softmax\", name=\"pred\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "model.compile(optimizer=Adam(learning_rate=0.000002),\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "logdir = os.path.join(\"../logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"../model/mymodel_best.h5\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=1e-4,\n",
    "        patience=16,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    TensorBoard(logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_data_gen,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plant_pred = model.predict(test_data_gen)\n",
    "test_df['plant'] = tf.math.argmax(plant_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare image generator\n",
    "train_disease_gen = train_image_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                           directory=\"../data/train\",\n",
    "                                                           x_col=\"filename\",\n",
    "                                                           y_col=\"disease\",\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           subset='training',\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(image_size,image_size),\n",
    "                                                           batch_size=batch)\n",
    "\n",
    "valid_disease_gen = train_image_generator.flow_from_dataframe(dataframe=train_df,\n",
    "                                                           directory=\"../data/train\",\n",
    "                                                           x_col=\"filename\",\n",
    "                                                           y_col=\"disease\",\n",
    "                                                           class_mode=\"categorical\",\n",
    "                                                           subset='validation',\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(image_size,image_size),\n",
    "                                                           batch_size=batch)\n",
    "\n",
    "test_disease_gen = test_image_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                                         directory=\"../data/test\",\n",
    "                                                         x_col=\"filename\",\n",
    "                                                         y_col=None,\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=False,\n",
    "                                                         target_size=(image_size,image_size),\n",
    "                                                         batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call bottom model\n",
    "inputs = Input(shape = (image_size, image_size, 3))\n",
    "bot_model = EfficientNetB2(weights='imagenet', input_tensor=inputs, classifier_activation=None, include_top=False)\n",
    "# Rebuild top\n",
    "x = GlobalAveragePooling2D(name=\"avg_pool\")(bot_model.output)\n",
    "x = BatchNormalization(name=\"bn_avg_pool\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(176, activation=\"swish\", name=\"top_dense_1\")(x)\n",
    "x = Dense(22, activation=\"relu\", name=\"top_dense_2\")(x)\n",
    "outputs = Dense(14, activation=\"softmax\", name=\"pred\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "disease_model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "disease_model.compile(optimizer=Adam(learning_rate=0.000002),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "logdir = os.path.join(\"../logs/disease\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "disease_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"../model/disease_mymodel_best.h5\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=1e-4,\n",
    "        patience=16,\n",
    "        verbose=1,\n",
    "    ),\n",
    "    TensorBoard(logdir, histogram_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = disease_model.fit(\n",
    "    train_disease_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_disease_gen,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_pred = disease_model.predict(test_disease_gen)\n",
    "test_df['disease'] = tf.math.argmax(disease_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"final_test_df.tsv\", sep='\\t', header = False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"final_test_df.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>plant</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>3992.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>3993.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>3994.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3995.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3996.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3997 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  plant  disease\n",
       "0        0.jpg      3        9\n",
       "1        1.jpg      3        8\n",
       "2        2.jpg      4        7\n",
       "3        3.jpg      4       11\n",
       "4        4.jpg      4        1\n",
       "...        ...    ...      ...\n",
       "3992  3992.jpg      2        3\n",
       "3993  3993.jpg      2        4\n",
       "3994  3994.jpg      2        5\n",
       "3995  3995.jpg      2        6\n",
       "3996  3996.jpg      2        8\n",
       "\n",
       "[3997 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
